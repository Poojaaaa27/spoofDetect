
# ğŸ§  Fourier-Aware Spoofing Attacks Detection with Lightweight CNN Architecture

## ğŸ“Œ Description
- Face recognition systems are increasingly deployed in security-sensitive environments (e.g., banking apps, smart devices, building access), but remain vulnerable to **presentation attacks** such as photos, videos, and 3D masks.
- These spoofing attacks can fool face recognition systems, posing serious security threats.
- **Silent face anti-spoofing** addresses this by detecting fake inputs **without requiring user interaction**, enabling a seamless and non-intrusive user experience.
- This project is inspired by [MiniVision AI's Silent-Face-Anti-Spoofing repository](https://github.com/minivision-ai/Silent-Face-Anti-Spoofing), and expands upon their work by refined  training methodologies with Fourier Transforms which is pruned and retrained version of MiniFASNet, carefully balancing model size and performance for real-time deployment and mobile readiness. and performance visualization.
- We implement a **two-branch architecture**:
  - **Primary Branch**: A lightweight CNN based on MiniFASNet for binary classification (real vs. spoof).
  - **Auxiliary Branch**: Incorporates **Fourier spectral supervision** to highlight frequency-domain differences between real and spoofed faces.
- The model uses **RetinaFace** for face detection and generates multiple patches at different scales (1.0Ã—, 2.7Ã—, 4.0Ã—) to improve robustness across spatial contexts.
- Each image undergoes **Fourier Transform** to extract frequency-based information, aiding in the detection of spoofing cues not visible in the spatial domain.
- The final training objective combines classification loss and auxiliary spectral loss:  

## Model Architecture

The following diagram illustrates the dual-branch model comprising MiniFASNet and Fourier Supervision:

![Architecture Diagram](images/architecture.png)

## ğŸ“ Directory Structure
```
.
â”œâ”€â”€ models/               # Pretrained models and checkpoints
â”œâ”€â”€ datasets/             # Organized dataset for training and testing
â”œâ”€â”€ src/                  # Source code
â”‚   â”œâ”€â”€ model/            # MiniFASNet and submodules
â”‚   â”œâ”€â”€ preprocessing/    # Face detection, patching, Fourier transform
â”‚   â””â”€â”€ utils/            # Helper functions
â”œâ”€â”€ images/               # Test images
â”œâ”€â”€ results/              # Output metrics and visualizations
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ train.py              # Training pipeline
â”œâ”€â”€ test.py               # Inference script
â””â”€â”€ README.md             # This file
```

## ğŸ§  Methodology
- **Architecture**: MiniFASNet (a pruned version of MobileFaceNet)
- **Supervision**: Dual-branch design with Fourier spectrum auxiliary loss
- **Detection**: Silent (non-intrusive), based solely on camera input
- **Inspiration**: MiniVisionâ€™s Silent Anti-Spoofing implementation

## ğŸ”§ Installation

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/silent-face-anti-spoofing.git
cd silent-face-anti-spoofing
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

## ğŸ—‚ï¸ Dataset Preparation

Ensure your training images are organized like this:
```
datasets/
â””â”€â”€ RGB_Images/
    â”œâ”€â”€ org_1_80x60/
    â”‚   â”œâ”€â”€ 0/  # Fake
    â”‚   â”œâ”€â”€ 1/  # Real
    â”‚   â””â”€â”€ 2/  # Others
    â”œâ”€â”€ 1_80x80/
    â””â”€â”€ ...
```

Each image must be resized and optionally patched (scaling: 1.0Ã—, 2.7Ã—, 4.0Ã—) using a face detector (RetinaFace). Fourier spectra are generated for each input as auxiliary supervision.

## ğŸ‹ï¸â€â™€ï¸ Training

```bash
python train.py --device_ids 0 --patch_info your_patch
```

The training optimizes the following loss:

```
L_total = L_cls + Î» * L_fourier
```

Where:
- `L_cls`: Binary cross-entropy for classification
- `L_fourier`: Auxiliary loss using Fourier spectral differences
- `Î»`: Loss balancing factor

## ğŸ§ª Inference

```bash
python test.py --image_name images/sample/your_image.png
```

The model will output:
- Confidence score
- Prediction (real/spoof)

## ğŸ“ˆ Results

| Model          | FLOPs   | Accuracy | TPR@FPR=1e-5 | Speed (ms) |
|----------------|---------|----------|--------------|-------------|
| MobileFaceNet   | 0.224G | 96.5%    | 94.1%        | 28ms        |
| MiniFASNetV1    | 0.081G | 97.2%    | 95.6%        | 25ms        |
| **MiniFASNetV2 (Ours)** | **0.081G** | **97.8%** | **97.8%**    | **20ms**    |

## ğŸ“Š Visual Outputs
- ![OUTPUT](./home.png)
- ![REGISTRATION PORTAL ](login.png)

Visualizations such as ROC curves and confusion matrices can be found in the `main/` file. These help compare model variants and evaluate classification behavior.


## ğŸ“œ Citation

For further research, consider citing:

```bibtex
@inproceedings{IEEE2025,
  title={Passive Detection of Spoofing Attacks in Facial Biometrics},
  author={Pooja J, poojaa1627@gmail.com},
  booktitle={International Conference on Advances in Computing,Communication and Applied Informatics(ACCAI-2025)},
  year={2025}
}
```


## ğŸ“¬ Contact
Contact info:

ğŸ“§ poojaa1627@gmail.com
